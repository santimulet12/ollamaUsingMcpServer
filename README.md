# Sistema de Chat con Herramientas MCP

Sistema de asistente conversacional que integra Ollama con herramientas MCP (Model Context Protocol) para obtener informaciÃ³n en tiempo real, como el clima de ciudades.

## ğŸ“‹ Requisitos Previos

- Python 3.11 o superior
- [uv](https://docs.astral.sh/uv/) instalado
- Ollama instalado y ejecutÃ¡ndose
- Modelo Qwen 2.5:3b descargado en Ollama
- ConexiÃ³n a internet

## ğŸ”§ InstalaciÃ³n

### 1. Instalar uv

**Linux/macOS:**
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
source $HOME/.local/bin/env
```

**Windows:**
```powershell
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"
```

### 2. Clonar o descargar el proyecto

```bash
git clone https://github.com/santimulet12/ollamaUsingMcpServer.git
cd ollamaUsingMcpServer
```

### 3. Instalar dependencias con uv

```bash
# uv automÃ¡ticamente crea el entorno virtual e instala todo
uv sync
```

Eso es todo. **No necesitas** ejecutar `pip install` manualmente.

### 4. Configurar Ollama

AsegÃºrate de que Ollama estÃ© instalado y ejecutÃ¡ndose. Si no lo tienes, instÃ¡lalo desde [ollama.ai](https://ollama.ai).

Descarga el modelo requerido:

```bash
ollama pull qwen2.5:3b
```

Verifica que Ollama estÃ© corriendo:

```bash
ollama list
```

### 5. Configurar la API

En el archivo `API.py`, modifica la lÃ­nea 9 con la direcciÃ³n IP correcta de tu servidor Ollama:

```python
OLLAMA_API_URL = "http://IP_AQUI:11434/api/chat"
```

Si Ollama estÃ¡ en la misma mÃ¡quina, usa:

```python
OLLAMA_API_URL = "http://localhost:11434/api/chat"
```

## ğŸš€ EjecuciÃ³n

### Paso 1: Iniciar el Servidor MCP

```bash
uv run python MCPServer.py
```

DeberÃ­as ver:

```
ğŸš€ Servidor MCP iniciado en http://localhost:8000/mcp
ğŸ“¡ Herramientas disponibles: obtener_clima
```

### Paso 2: Iniciar la API Flask

En otra terminal (dejando el servidor MCP corriendo):

```bash
uv run python API.py
```

La API Flask se iniciarÃ¡ en `http://localhost:5000`

## ğŸ“¡ Uso de la API

### Endpoint de Chat

**URL:** `POST http://localhost:5000/ask-ia`

**Body (JSON):**

```json
{
  "prompt": "Â¿CÃ³mo estÃ¡ el clima en Buenos Aires?",
  "historial": []
}
```

**Ejemplo con historial:**

```json
{
  "prompt": "Â¿Y en Madrid?",
  "historial": [
    {"role": "user", "content": "Â¿CÃ³mo estÃ¡ el clima en Buenos Aires?"},
    {"role": "assistant", "content": "En Buenos Aires hace 22Â°C..."}
  ]
}
```

**Respuesta:**

```json
{
  "response": "En Buenos Aires actualmente hay 22Â°C con cielo despejado. La sensaciÃ³n tÃ©rmica es de 21Â°C y hay un 65% de humedad."
}
```

### Endpoint para verificar el estado de la API

**URL:** `GET http://localhost:5000/health`

**Respuesta:**

```json
{
  "status": "ok"
}
```

## ğŸ› ï¸ Herramientas Disponibles

### obtener_clima

Obtiene informaciÃ³n meteorolÃ³gica actual de cualquier ciudad del mundo.

**ParÃ¡metros:**
- `ciudad` (string): Nombre de la ciudad (ej: "Buenos Aires", "Madrid", "New York")

**InformaciÃ³n retornada:**
- Temperatura actual y sensaciÃ³n tÃ©rmica
- DescripciÃ³n del clima
- Humedad
- Velocidad del viento
- PresiÃ³n atmosfÃ©rica
- Visibilidad
- Ãndice UV

## ğŸ§ª Ejemplos de Uso

### Usando cURL:

```bash
curl -X POST http://localhost:5000/ask-ia \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Â¿QuÃ© tiempo hace en Mendoza?"}'
```

### Usando Python:

```python
import requests

response = requests.post(
    "http://localhost:5000/ask-ia",
    json={
        "prompt": "Â¿CÃ³mo estÃ¡ el clima en Londres?",
        "historial": []
    }
)

print(response.json()["response"])
```

## ğŸ”§ Comandos Ãºtiles con uv

```bash
# Agregar una nueva dependencia
uv add nombre-paquete

# Agregar dependencia de desarrollo
uv add --dev nombre-paquete

# Ejecutar scripts
uv run python MCPServer.py
uv run python API.py

# Actualizar dependencias
uv lock --upgrade

# Ver dependencias instaladas
uv pip list

# Ver Ã¡rbol de dependencias
uv pip tree
```

## ğŸ› SoluciÃ³n de Problemas

### El servidor MCP no inicia

- Verifica que el puerto 8000 no estÃ© en uso
- AsegÃºrate de que todas las dependencias estÃ©n instaladas: `uv sync`

### La API Flask no se conecta a Ollama

- Verifica que Ollama estÃ© corriendo: `ollama list`
- Confirma que la URL en `API.py` sea correcta
- AsegÃºrate de que el modelo `qwen2.5:3b` estÃ© descargado

### Error de conexiÃ³n al servidor MCP

- Verifica que `MCPServer.py` estÃ© corriendo con `uv run python MCPServer.py`
- Confirma que estÃ© accesible en `http://localhost:8000/mcp`

### El modelo no usa las herramientas correctamente

- El modelo debe responder en el formato exacto: `USE_TOOL:` y `ARGS:`
- Si no funciona, considera ajustar el `SYS_PROMPT` en `API.py`

### Problemas con el entorno virtual

```bash
# Eliminar el entorno y reinstalar
rm -rf .venv uv.lock
uv sync
```

## ğŸ“¦ Estructura del Proyecto

```
mcp-chat-system/
â”œâ”€â”€ .venv/                  # Entorno virtual (creado por uv)
â”œâ”€â”€ API.py                  # API Flask principal
â”œâ”€â”€ MCPServer.py            # Servidor MCP con herramientas
â”œâ”€â”€ Documentacion.md        # DocumentaciÃ³n tÃ©cnica
â”œâ”€â”€ README.md               # Este archivo
â”œâ”€â”€ pyproject.toml          # ConfiguraciÃ³n del proyecto y dependencias
â”œâ”€â”€ uv.lock                 # Lock file para reproducibilidad
â””â”€â”€ .python-version         # VersiÃ³n de Python fijada
```

## ğŸ“ Notas

- El servidor MCP debe estar corriendo antes de iniciar la API Flask
- El servicio de clima usa `wttr.in`, que es gratuito pero puede tener lÃ­mites de uso
- Las respuestas estÃ¡n configuradas para ser concisas (3-4 oraciones mÃ¡ximo)
- Todo el sistema estÃ¡ configurado para responder en espaÃ±ol
- **uv** gestiona automÃ¡ticamente las dependencias y el entorno virtual
- No necesitas activar manualmente el entorno virtual, usa `uv run`

## ğŸš€ Ventajas de usar uv

- âš¡ **10-100x mÃ¡s rÃ¡pido** que pip
- ğŸ”’ **Lock file automÃ¡tico** para reproducibilidad
- ğŸ“¦ **GestiÃ³n unificada** de dependencias y Python
- ğŸ¯ **Un solo archivo** de configuraciÃ³n (pyproject.toml)
- ğŸ”„ **SincronizaciÃ³n perfecta** entre entornos